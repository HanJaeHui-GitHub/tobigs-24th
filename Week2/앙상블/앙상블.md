# 앙상블(Ensemble)

여러 개의 모델을 결합하여 하나의 모델보다 더 좋은 성능을 내도록 하는 기법

No Free Lunch Theorem : 모든 문제에 항상 성능이 좋은 단일 알고리즘은 존재하지 않는다

$\hookrightarrow$ 특정 데이터셋에서만 잘 작동하는 단일 모델보다 다양한 모델의 강점을 결합해 여러 상황에서도 안정적으로 좋은 성능을 낼 수 있는 새로운 모델 필요

Diversity Theorem : 서로 다른 관점을 가진 모델들을 조합할수록 전체 모델의 성능이 높아질 수 있다

$\hookrightarrow$ 각 모델이 서로 다른 방식으로 데이터를 해석하고 예측한다면 더 강력한 예측력을 가질 수 있음


**Bias-Variance Trade-off**

- 이상적인 경우 = Low Bias, Low Vaiance

  예측이 정답 중심에 모여 있어 오차가 작고 안정적임

  데이터의 복잡한 패턴은 잘 포착하면서 불필요한 노이즈에 과하게 반응하지 않음

  학습과 일반화가 균형을 이룸

- 편향이 큰 경우(High Bias, Low Variance)

  예측이 한쪽으로 일관되게 빗나감

  모델이 단순하여 복잡한 패턴 학습에 실패함 = **과소적합(Underfitting)** 상태

- 분산이 큰 경우(Low Bias, High Variance)

  예측이 정답 근처이지만 산발적으로 흩어짐

  모델이 너무 복잡하여 데이터에 과민 반응함 = **과대적합(Overfitting)** 상태
  

$$
\begin{align}
MSE(x)& = E_{D, \epsilon}[(y-\hat{f(x)})^2] \\
& = (E_D[\hat{f(x)})^2] - f(x))^2+E_D[(\hat{f(x)}-E_D[\hat{f(x)}])^2]+\sigma^2 \\
& = Bias^2 + Variance + Noise \\
\\
Bias^2& = (E_D[\hat{f(x)})^2] - f(x))^2\ \text{: 예측값의 평균과 실제 정답 사이의 차이} \\
Variance & = E_D[(\hat{f(x)}-E_D[\hat{f(x)}])^2]\ \text{: 예측값의 변동성} \\
Noise & = \sigma^2\ \text{: 데이터 자체에 내재된 잡음}
\end{align}
$$

$Variance = E_D[(\hat{f(x)}-E_D[\hat{f(x)}])^2]\downarrow\ \text{: Bagging}$

$Bias^2 = (E_D[\hat{f(x)})^2] - f(x))^2\downarrow\ \text{: Boosting}$

-----

## Voting

여러 개의 서로 다른 모델들의 예측 결과를 투표 방식으로 결합하는 방법

- **Hard Voting**

  각 모델이 예측한 클래스 중 가장 만히 선택된 것을 최종 예측값으로 결정하는 다수결 방식

  주로 분류(Classification)에 사용

- **Soft Voting**

  각 모델이 예측한 클래스의 확률값 또는 예측값을 평균낸 뒤 가장 높은 확률을 가진 클래스를 선택하는 방식

  분류(Classification)뿐 아니라 회귀(Regression)에도 사용

-----

## Bagging(Bootstrap Aggregating)
동일한 모델을 학습시켜 예측 결과를 통합하는 방법 = Aggregating

모집단으로부터 중복을 허용하여 표본을 추출하는 방식

전체 훈련 데이터셋에서 중복 허용 샘플링을 통해 여러 개의 훈련 데이터셋을 만듦

> 각 샘플은 복수의 부트스트랩 샘플에 포함될수도, 아예 포함되지 않을 수도 있음

> 각 샘플은 독립적인 모델 학습에 사용됨

> 서로 다른 샘플을 기반으로 학습됨 모델들은 각자 조금씩 다른 관점의 학습을 하게 됨

- **Bootstrap**

  훈련 데이터셋에서 중복을 허용하여 샘플링

  부스스트랩 과정에서 한번도 뽑히지 않은 데이터 = **Out-of-Bag(OOB)샘플**

  OOB 샘플을 활용하여 해당 모델의 전체 성능 평가 = **Out-of_Bag(OOB) 평가**

일반적으로 복잡한 패턴을 잘 삭습할 수 있는 복잡도(Complexity)가 높은 모델(ex.Decision Tree, SVM)과 함께 사용

복잡한 모델은 데이터에 지나치게 민감하게 반응하여 과적합 위험이 크기 때문에 Bagging을 통해 예측의 분산을 줄이고 보다 안정적인 성능 얻을 수 있음

### Random Forest

여러 개의 Decision Tree를 학습시키고 그 결과를 종합하여 최종 예측을 수행하는 앙상블 모델

1. Bootstrap = Decision Tree

   각각의 Tree는 Bootstrap Sampling을 통해 만들어진 서로 다른 데이터셋을 학습

2. Random Feature Selection

   일반적인 Decision Tree는 모든 피처 대상으로 정보이득이나 지니 지수가 가장 좋은 피처를 선택하지만 Random Forest는 랜덤으로 선택된 일부 피터만 고려하여 분기 형성

3. Aggregation

   학습된 개별 Tree들의 예측을 통합하여 최종 예측 수행

   $\hookrightarrow$ 개별 Decision Tree보다 훨씬 뛰어난 일반화 성능을 갖게 되며 과적합을 방지하면서도 복잡한 데이터의 패턴을 잘 포착할 수 있음

5. Out-of-Bag Evaluation

   각각의 Tree는 Bootstrap Sampling을 통해 만들어진 일부 데이터만 학습하기 때문에 학습에 사용되지 않은 나머지 데이터 OOB를 점증 데이터로 활용하여 모델 성능 평가

   $\hookrightarrow$ 별도의 검증 데이터셋을 만들 필요 없음, 교차 검증 수준의 신뢰도 있는 성능 평가 제공, 데이터가 충분하지 않을 때 유용
   
- Permutation Importance

  특정 변수의 값을 무작위로 섞어 모델의 성능 저하 정도를 확인하는 방식

$$
\begin{align}
\text{OOB로 원래 모델 오차 :}\ p_i \\
\text{변수 $i$의 값을 임의로 섞은 모델 오차 :}\ e_i\\
\text{두 모델 오차 차이 :}\ p_i - e_i = d_i\\
\\
d_i\text{가 클수록 해당 변수$(i)$를 섞었을 때 성능이 많이 떨어진다는 것} \rightarrow \text{예측에 중요한 역할}\\
d_i\text{가 작을수록 해당 변수$(i)$를 섞어도 성능 변화가 적다는 것} \rightarrow \text{예측에 거의 기여하지 않음}
\end{align}
$$

$$
\begin{align}
\text{기존 } m \text{번째 트리에서의 오차 : } p_i^m \\
\text{변수 } i \text{의 값을 임의로 섞은 모델의 } m \text{번째 트리에서의 오차 : } e_i^m \\
\text{두 오차의 차이 : } p_i^m - e_i^m = d_i^m \\
\text{변수 } i \text{의 값을 섞었을 때 성능 변화의 평균 : } 
   \bar{d_i} = \frac{1}{m}\sum_{j=1}^m d_i^j \\
\text{변수 } i \text{의 값을 섞었을 때 성능 변화의 분산 : } 
   s_i^2 = \frac{1}{m-1}\sum_{j=1}^m \left(d_i^j- \bar{d_i}\right)^2 \\
\text{변수 } i \text{의 importance : } v_i = \frac{\bar{d_i}}{s_i^2}
\end{align}
$$

-----

## Boosting

여러 개의 약한 학습기를 순차적으로 학습시켜 강한 학습기를 만드는 방법

각 단계에서 이전 모델이 잘못 예측한 데이터에 더 큰 가중치를 부여하여 이후 모델이 올바르게 예측할 수 있도록 학습

모델이 점점 복잡해지면서 편향이 줄어들고 과소적합 문제 완화

비교|학습 방법|방법|효과
-|-|-|-
Bagging|각 모델이 독립적으로 병렬 학습|부트스트랩 샘플링|분산 감소
Boosting|이전 모델의 결과를 반영하여 순차적 학습|오답 데이터에 대해 가중치 부여|편향 감소

### AdaBoost(Adaptive Boost)

과정
1. 가중치 초기화  $w_i^{(1)}=\frac{1}{N}, i = 1,2, \cdots, N$
2. T번째 약한 학습기 훈련  $t = 1,2, \cdots, T$
3. 오차율 계산  $\epsilon_t = \displaystyle\sum_{i=1}^N w_i^{(t)}\mathbb{I}(h_t(x_i) \neq y_i)$
4. 학습기 성능 반영 가중치 계산  $\alpha_t = \frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t})
5. 샘플 가중치 업데이트  $w_i^{(t+1)} = \frac{w_i^{(t)} \cdot \exp\big(-\alpha_t y_i h_t(x_i)\big)}{Z_t}, 
\quad
Z_t = \sum_{i=1}^N w_i^{(t)} \cdot \exp\big(-\alpha_t y_i h_t(x_i)\big)$
6. 최종 예측 모델  $H(x) = sign(\displaystyle\sum_{t=1}^T \alpha_t h_t(x))$

학습기 업데이트 과정에서 예측값이 얼마나 틀렸는지가 아닌 맞았는지 틀렸는지만 보고 가중치 조절함

$\hookrightarrow$ 유연성이 떨어지고 회귀 문제에 적용 어려움, MSE, 로그 손실과 같은 다양한 손실 함수 사용 어려움

### GBM(Gradient Boosting)

경사하강법(Gradient Descent)을 활용해 손실 함수의 최소화하는 방향으로 다음 학습기 학습

목표 : 실제 값과 예측 값 사이의 오차 줄이기 = 손실 함수 최소화 = 손실함수 Gradient를 최소화하는 가중치 값을 구함

과정
1. 초기 모델 설정  $\min_F \sum_{i=1}^n \mathcal{L}\left(y_i, F(x_i)\right)$
2. 잔차(Gradient) 계산  $r_i^{(m)} = - \left[\frac{\partial \mathcal{L}(y_i, F(x_i))}{\partial F(x_i)} \right]\_{F(x)=F_{m-1}(x)}, 
\quad m = 1, 2, \ldots, M$
3. 잔차 예측 모델 학습  $h_m(x) \approx r_i^{(m)},\ \gamma_m = \arg\min_{\gamma} \sum_{i=1}^n  \mathcal{L}\left(y_i, F_{m-1}(x_i) + \gamma h_m(x_i)\right)$
4. 이전 예측에 새로운 모델 추가  $F_m(x) = F_{m-1}(x) + \nu \gamma_m h_m(x),\ F_M(x) = F_0(x) + \sum_{m=1}^M \nu \gamma_m h_m(x)$

손실함수를 최소화하기 위한 계산을 순차적으로 함

$\hookrightarrow$ 학습 속도 느림, 과적합 가능성 큼, 대용량이나 고차원 데이터에서 계산 비용 급증\

### XGBoost(eXtreme Gradient Boosting)

GBM을 기반으로 하면서 성능과 효율성 모두 향상시킨 알고리즘

- 병렬 처리(Parallelization)

  트리 분할 과정에서 가능한 분할 후보들을 미리 계산하고 이를 병렬로 처리할 수 있도록 구현

- 정규화(Regularization)

  L1, L2 정규화 항을 추가하여 모델의 복잡도를 제어하고 과적합 방지
  

### LightGBM

리프 중심 트리 분할 방식을 통해 학습 속도와 예측 성능을 개선한 알고리즘

대용량 데이터 처리에 최적화, GPU 학습, 범주형 변수 자동 처리

### CatBoost

범주형 변수 처리에 특화된 알고리즘

별도의 인코딩 없이 높은 성능을 낼 수 있음

순서를 고려한 학습 방식과 정교한 정규화를 통해 과적합 방지하고 안정적인 성능 제공

------

## Blending & Stacking

여러 베이스 모델의 예측 값을 입력으로 메타 모델을 학습해 최종 예측을 수행하는 방식

- 기본 모델(Base Model) : 예측을 개별적으로 수행하는 모델

- 메타 모델(Meta Model) : 기본 모델들이 만든 예측을 다시 입력으로 받아 최종 예측을 수행하는 모델

### Blending

Holdout(Validation) 데이터 부분만 따로 떼어 메타 모델을 학습시키는 구조

Train / Holdout / Test set 분할

과정
1. Train 데이터로 여러 Base 모델 학습
2. Base 모델들로 Holdout 데이터에 대한 예측 수행
3. Base 모델의 예측 값들을 모아 입력 Feature로 사용하여 Meta 모델 학습
4. Base 모델들로 Test 데이터에 대한 예측, 이 예측 값들로 Meta 모델 최종 예측 수행

### Stacking

K-Fold로 모든 데이터를 빠짐없이 사용하여 보다 일반화된 예측을 수행하는 방식

Train(K-Fold) / Test set 분할

과정
1. Train 데이터로 여러 Base 모델 학습, K-Fold CV 수행
2. 각 Fold의 예측 값들을 모아(쌓아) 입력 Feature로 사용하여 Meta 모델 학습
3. Base 모델들로 Test 데이터에 대해 예측, 이 예측 값들로 Meta 모델 최종 예측 수행
